{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import mlflow\n",
    "\n",
    "# Import custom functions from src folder\n",
    "import sys\n",
    "sys.path.append('../src')  # Add src folder to Python path\n",
    "from data_preprocessing import (\n",
    "    handle_missing_values,\n",
    "    clean_data,\n",
    "    perform_eda,\n",
    "    merge_geolocation_data,\n",
    "    feature_engineering,\n",
    "    normalize_data,\n",
    "    encode_categorical_features,\n",
    ")\n",
    "from model_training import (\n",
    "    prepare_data,\n",
    "    select_model,\n",
    "    train_and_evaluate,\n",
    "    log_experiment,\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_country_data = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "creditcard_data = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "# Display dataset summaries\n",
    "print(\"Fraud Data Summary:\")\n",
    "print(fraud_data.info())\n",
    "print(\"\\nIP Country Data Summary:\")\n",
    "print(ip_country_data.info())\n",
    "print(\"\\nCredit Card Data Summary:\")\n",
    "print(creditcard_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Data Analysis and Preprocessing\n",
    "# 1. Handle Missing Values\n",
    "faud_data = handle_missing_values(fraud_data, strategy='drop')\n",
    "creditcard_data = handle_missing_values(creditcard_data, strategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "fraud_data = clean_data(fraud_data)\n",
    "creditcard_data = clean_data(creditcard_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "print(\"Fraud Data EDA:\")\n",
    "perform_eda(fraud_data)\n",
    "print(\"\\nCredit Card Data EDA:\")\n",
    "perform_eda(creditcard_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge Datasets for Geolocation Analysis\n",
    "merged_fraud_data = merge_geolocation_data(fraud_data, ip_country_data)\n",
    "\n",
    "# 5. Feature Engineering\n",
    "merged_fraud_data = feature_engineering(merged_fraud_data)\n",
    "creditcard_data = feature_engineering(\n",
    "    creditcard_data\n",
    ")  # Add time-based features if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Normalization and Scaling\n",
    "numerical_features = [\n",
    "    \"purchase_value\",\n",
    "    \"age\",\n",
    "    \"transaction_frequency\",\n",
    "    \"transaction_velocity\",\n",
    "]\n",
    "merged_fraud_data = normalize_data(merged_fraud_data, numerical_features)\n",
    "\n",
    "# 7. Encode Categorical Features\n",
    "categorical_features = [\"source\", \"browser\", \"sex\"]\n",
    "merged_fraud_data = encode_categorical_features(merged_fraud_data, categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Model Building and Training\n",
    "\n",
    "# 1. Data Preparation\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = prepare_data(\n",
    "    merged_fraud_data, target_column=\"class\"\n",
    ")\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = prepare_data(\n",
    "    creditcard_data, target_column=\"Class\"\n",
    ")\n",
    "\n",
    "# 2. Model Selection\n",
    "models = [\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTree\",\n",
    "    \"RandomForest\",\n",
    "    \"GradientBoosting\",\n",
    "    \"MLP\",\n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\nTraining {model_name} on Fraud Data:\")\n",
    "    model = select_model(model_name)\n",
    "    train_and_evaluate(model, X_train_fraud, y_train_fraud, X_test_fraud, y_test_fraud)\n",
    "\n",
    "    print(f\"\\nTraining {model_name} on Credit Card Data:\")\n",
    "    model = select_model(model_name)\n",
    "    train_and_evaluate(\n",
    "        model, X_train_credit, y_train_credit, X_test_credit, y_test_credit\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Log Experiments with MLflow\n",
    "params = {\"model\": \"RandomForest\", \"dataset\": \"Fraud Data\"}\n",
    "metrics = {\"roc_auc\": roc_auc_score(y_test_fraud, model.predict(X_test_fraud))}\n",
    "log_experiment(model, params, metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
